# Pipeline de Dados em Tempo Real com PostgreSQL, Debezium, Kafka e Druid via Docker-Compose


## √çndice

1. [Objetivo](#1-objetivo)
2. [Componentes](#2-componentes)
3. [Infraestrutura Utilizada](#3-infraestrutura-utilizada)
4. [Arquitetura Docker Compose](#4-arquitetura-docker-compose)

   * Tabela de Produtos, Portas, Vers√µes e Observa√ß√µes
5. [Guia de Uso Local](#5-guia-de-uso-local)

   * Pr√©-requisitos
   * Instala√ß√£o
   * Teste do Laborat√≥rio

     * Cria√ß√£o da Tabela
     * Cria√ß√£o do Conector Debezium
     * Exclus√£o do Conector
     * Verifica√ß√£o de T√≥picos Kafka
     * Inser√ß√£o de Dados
     * Verifica√ß√£o do T√≥pico Kafka
     * Consumindo T√≥picos no Druid
6. [Conclus√£o](#conclus√£o)

---

## 1. Objetivo

Criar um fluxo streaming iniciando no PostgreSQL, onde a inser√ß√£o de dados em uma tabela ser√° capturada pelo Debezium, enviada ao Kafka e consumida pelo Druid para visualiza√ß√£o e an√°lise.

---

## 2. Componentes

* **PostgreSQL**: Base de dados relacional que serve como origem dos dados a serem capturados.
* **Debezium**: Ferramenta de captura de dados em tempo real (CDC) que detecta altera√ß√µes no PostgreSQL via replica√ß√£o l√≥gica e publica no Kafka.
* **Kafka**: Sistema de mensageria distribu√≠da que recebe os eventos do Debezium e os distribui para consumidores.
* **Zookeeper**: Servi√ßo de coordena√ß√£o usado pelo Kafka para gerenciamento de metadados e orquestra√ß√£o dos brokers.
* **Druid**: Plataforma anal√≠tica que consome os t√≥picos do Kafka e permite a visualiza√ß√£o dos dados em tempo real atrav√©s de dashboards.

---

## 3. Infraestrutura Utilizada

* Servidor Virtual: 16GB RAM, 40GB Disco, 2 vCPU.

---

## 4. Arquitetura Docker Compose


### Tabela de Produtos, Portas, Vers√µes e Observa√ß√µes

| Produto             | Porta(s)                 | Vers√£o | Observa√ß√£o                                                                                                                                        |
| ------------------- | ------------------------ | ------ | ------------------------------------------------------------------------------------------------------------------------------------------------- |
| PostgreSQL          | 5432:5432                | 15     | `wal_level=logical` habilitado para replica√ß√£o l√≥gica.                                                                                            |
| Zookeeper           | 2181:2181                | 6.1.1  | Imagem `confluentinc/cp-zookeeper`. Compat√≠vel com Zookeeper 3.7.2.                                                                               |
| Kafka               | 29092:29092, 29093:29093 | 6.1.1  | Imagem `confluentinc/cp-kafka`. Compat√≠vel com Kafka 2.8.2. Configurado com m√∫ltiplos listeners (`PLAINTEXT`, `PLAINTEXT_HOST`, `PLAINTEXT_EXT`). |
| Debezium            | 8085:8083                | 2.7    | Servi√ßo de captura CDC.                                                                                                                           |
| Druid Coordinator   | 8081:8081                | 30.0.0 | Gerencia segmenta√ß√£o de dados.                                                                                                                    |
| Druid Broker        | 8082:8082                | 30.0.0 | Intermedi√°rio de consultas.                                                                                                                       |
| Druid Historical    | 8083:8083                | 30.0.0 | Armazena dados segmentados.                                                                                                                       |
| Druid MiddleManager | 8091:8091, 8100‚Äì8105     | 30.0.0 | Processa ingest√µes.                                                                                                                               |
| Druid Router        | 8888:8888                | 30.0.0 | Interface web e roteamento de APIs.                                                                                                               |

---


üîé *Observa√ß√£o:*

**Confluentinc**: Distribui√ß√£o da Confluent que integra Kafka e Zookeeper com ferramentas adicionais. A imagem `confluentinc/cp-kafka:6.1.1` **inclui Kafka 2.8.2 e Zookeeper 3.7.2**, de acordo com a [tabela de interoperabilidade da Confluent](https://docs.confluent.io/platform/6.1/installation/versions-interoperability.html#interoperability-versions).


![Containers Docker](./assets/containers_docker.png)

*Figura 1: Containers Docker rodando*

---

## 5. Guia de Uso

### Pr√©-requisitos

* Docker
* Docker Compose
* Git

### Instala√ß√£o

1. Clone o projeto:

```bash
git clone https://github.com/filipe-oliv95/kafka-druid-pipeline.git
cd kafka-druid-pipeline
```

2. Suba os containers:

```bash
docker compose up -d
```

### Teste do Laborat√≥rio

#### Cria√ß√£o da Tabela

Acesse o container PostgreSQL e crie a tabela de exemplo:

```bash
docker exec -it postgres psql -U druid -d druid

CREATE TABLE products (
  id SERIAL PRIMARY KEY,
  name TEXT NOT NULL,
  price DECIMAL
);
```

#### Cria√ß√£o do Conector Debezium

Execute o comando abaixo em um terminal Linux para criar o conector:

```bash
curl -X POST http://localhost:8085/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "postgres-products-connector",
    "config": {
      "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
      "plugin.name": "pgoutput",
      "database.hostname": "postgres",
      "database.port": "5432",
      "database.user": "druid",
      "database.password": "FoolishPassword",
      "database.dbname": "druid",
      "database.server.name": "druidserver",
      "table.include.list": "public.products",
      "slot.name": "products_slot",
      "publication.autocreate.mode": "filtered",
      "database.include.schema.changes": "false",
      "tombstones.on.delete": "false",
      "key.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "topic.prefix": "products"
    }
  }'
```

> Obs: para excluir o conector:
>
> ```bash
> curl -X DELETE http://localhost:8085/connectors/postgres-products-connector  
> ```


#### Verifica√ß√£o de T√≥picos Kafka

```bash
docker exec -it kafka bash
kafka-topics --bootstrap-server localhost:9092 --list
```

![Topicos Kafka](./assets/topicos_kafka.png)

*Figura 2: T√≥picos Kafka padr√£o*

#### Inser√ß√£o de Dados no PostgreSQL

```bash
docker exec -it postgres psql -U druid -d druid

INSERT INTO products (name, price) VALUES
('Terno', 500.00);
```

#### Verifica√ß√£o do T√≥pico Kafka

```bash
docker exec -it kafka bash
kafka-topics --bootstrap-server localhost:9092 --list
```

![Topicos Kafka](./assets/topicos_kafka_2.png)

*Figura 3: Novo t√≥pico Kafka criado*



#### Consumindo T√≥picos no Druid

1. **Acesse a interface do Druid**

   Abra o navegador e v√° at√© o console do Druid:
   [http://localhost:8888/](http://localhost:8888/)

2. **Inicie o processo de ingest√£o de dados via Kafka**

   No menu lateral, v√° em:
   **Load Data** ‚Üí **Streaming** ‚Üí **Kafka**

3. **Configure a conex√£o com o Kafka**

   Preencha os seguintes campos:

   * `Bootstrap servers`: `kafka:9092`

     > Endere√ßo do broker Kafka que o Druid ir√° se conectar.
   * `Topic`: `products.public.products`

     > Nome do t√≥pico Kafka que cont√©m os dados a serem consumidos.

   Ap√≥s preencher, clique em **Apply**.

   ![T√≥picos Kafka na interface web](./assets/topicos_kafka_web.png)
   *Figura 4: Configura√ß√£o do t√≥pico Kafka no Druid*

4. **Avance para o pr√≥ximo passo**

   Clique em **Next: Parse Data** para continuar com a defini√ß√£o do formato dos dados recebidos.

5. **Parse dos dados (defini√ß√£o do formato)**

   Nesta etapa, o Druid tentar√° detectar automaticamente o formato das mensagens do t√≥pico Kafka. Caso os dados estejam em **JSON**, como √© comum com eventos do Debezium, voc√™ ver√° uma pr√©via dos registros.

   * Confirme se os dados est√£o sendo reconhecidos corretamente.
   * Caso necess√°rio, ajuste manualmente o parser (por exemplo, definindo o formato como `json` ou `avro`, dependendo do seu caso).
   * Clique em **Next: Transform**.

6. **Transforma√ß√µes (opcional)**

   Aqui √© poss√≠vel aplicar transforma√ß√µes nos dados antes da ingest√£o, como renomear colunas, aplicar filtros ou express√µes.

   * Se n√£o for necess√°rio transformar os dados neste momento, apenas clique em **Next: Filter**.

7. **Filtros (opcional)**

   Permite filtrar os dados que ser√£o ingeridos, com base em condi√ß√µes nos campos.

   * Caso deseje ingerir todos os dados, clique diretamente em **Next: Configure schema**.

8. **Configura√ß√£o do schema**

   Nessa etapa, voc√™ define:

   * **Timestamp column**: o campo que ser√° usado como refer√™ncia temporal no Druid (por padr√£o, o Debezium envia um campo `ts_ms` com o timestamp da altera√ß√£o).

   * **Dimensions**: campos que ser√£o usados como atributos categ√≥ricos (ex: `name`, `color`).

   * **Metrics**: campos num√©ricos para agrega√ß√µes (ex: `standardCost`, `listPrice`).

   Ap√≥s configurar, clique em **Next: Tune**.

9. **Tuning (opcional)**

   Permite ajustes de performance e paralelismo da tarefa de ingest√£o. Se voc√™ n√£o tiver necessidades espec√≠ficas, pode deixar os valores padr√£o e clicar em **Next: Publish**.

10. **Publica√ß√£o da Tarefa de Ingest√£o**

    * D√™ um nome √† ingest√£o, como `kafka-products-ingestion`.
    * Revise todas as configura√ß√µes.
    * Clique em **Submit** para iniciar o processo.

---

## Conclus√£o

Este projeto demonstrou, de forma pr√°tica, a constru√ß√£o de um fluxo de dados em tempo real utilizando tecnologias modernas de streaming:

* **PostgreSQL** como fonte de dados transacionais;
* **Debezium** para captura de altera√ß√µes (CDC) via replica√ß√£o l√≥gica;
* **Kafka** como barramento de eventos distribu√≠do;
* **Druid** como plataforma anal√≠tica para ingest√£o e visualiza√ß√£o de dados.

A arquitetura implementada permite que qualquer altera√ß√£o na base PostgreSQL seja refletida em tempo real nos dashboards do Druid. Essa abordagem √© altamente escal√°vel, ideal para sistemas de monitoramento, an√°lise de logs, m√©tricas de neg√≥cios, entre outros casos de uso orientados a eventos.

Com o ambiente todo orquestrado via Docker Compose, a replica√ß√£o do laborat√≥rio em outras m√°quinas √© simples, facilitando testes, aprendizado e expans√£o para projetos maiores.

---

## Refer√™ncias

 [Kafka Docker-Compose Reference - GitHub](https://github.com/adityajoshi12/kafka-nodejs)

 [Druid Docker-Compose Reference - GitHub](https://github.com/apache/druid/tree/33.0.0#)

 [Druid Documentation](https://druid.apache.org/docs/latest/tutorials/docker)
