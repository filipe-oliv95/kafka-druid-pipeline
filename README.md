# Pipeline de Dados em Tempo Real com PostgreSQL, Debezium, Kafka e Druid via Docker-Compose


## √çndice

1. [Objetivo](#1-objetivo)
2. [Componentes](#2-componentes)
3. [Infraestrutura Utilizada](#3-infraestrutura-utilizada)
4. [Arquitetura Docker Compose](#4-arquitetura-docker-compose)
   * Tabela de Produtos, Portas, Vers√µes e Observa√ß√µes
5. [Guia de Uso Local](#5-guia-de-uso-local)
   * Pr√©-requisitos
   * Instala√ß√£o
   * Teste do Laborat√≥rio
6. [Conclus√£o](#6-conclus√£o)
7. [Refer√™ncias](#7-refer√™ncias)

---

## 1. Objetivo

Criar um fluxo streaming iniciando no PostgreSQL, onde a inser√ß√£o de dados em uma tabela ser√° capturada pelo Debezium, enviada ao Kafka e consumida pelo Druid para visualiza√ß√£o e an√°lise.

Como recurso adicional, foram inclu√≠dos o Apache Ranger (para controle de acesso e auditoria) e o Solr (como backend de auditoria).

---

## 2. Componentes

* **PostgreSQL**: Base de dados relacional que serve como origem dos dados a serem capturados.
* **Debezium**: Ferramenta de captura de dados em tempo real (CDC) que detecta altera√ß√µes no PostgreSQL via replica√ß√£o l√≥gica e publica no Kafka.
* **Kafka**: Sistema de mensageria distribu√≠da que recebe os eventos do Debezium e os distribui para consumidores.
* **Zookeeper**: Servi√ßo de coordena√ß√£o usado pelo Kafka para gerenciamento de metadados e orquestra√ß√£o dos brokers.
* **Druid**: Plataforma anal√≠tica que consome os t√≥picos do Kafka e permite a visualiza√ß√£o dos dados em tempo real atrav√©s de dashboards.
* **Apache Ranger**: Servi√ßo centralizado de pol√≠ticas de seguran√ßa e auditoria para componentes do ecossistema Hadoop, como Kafka e Druid.
* **Apache Solr**: Armazenamento das auditorias geradas pelo Ranger.

---

## 3. Infraestrutura Utilizada

* Servidor Virtual: 16GB RAM, 40GB Disco, 2 vCPU.

---

## 4. Arquitetura Docker Compose


### Tabela de Produtos, Portas, Vers√µes e Observa√ß√µes

| Produto             | Porta(s)                 | Vers√£o | Observa√ß√£o                                                                                                                                        |
| ------------------- | ------------------------ | ------ | ------------------------------------------------------------------------------------------------------------------------------------------------- |
| PostgreSQL          | 5432:5432                | 15     | `wal_level=logical` habilitado para replica√ß√£o l√≥gica.                                                                                            |
| Zookeeper           | 2181:2181                | 6.1.1  | Imagem `confluentinc/cp-zookeeper`. Compat√≠vel com Zookeeper 3.7.2.                                                                               |
| Kafka               | 29092:29092, 29093:29093 | 6.1.1  | Imagem `confluentinc/cp-kafka`. Compat√≠vel com Kafka 2.8.2. Configurado com m√∫ltiplos listeners (`PLAINTEXT`, `PLAINTEXT_HOST`, `PLAINTEXT_EXT`). |
| Debezium            | 8085:8083                | 2.7    | Servi√ßo de captura CDC.                                                                                                                           |
| Druid Coordinator   | 8081:8081                | 30.0.0 | Gerencia segmenta√ß√£o de dados.                                                                                                                    |
| Druid Broker        | 8082:8082                | 30.0.0 | Intermedi√°rio de consultas.                                                                                                                       |
| Druid Historical    | 8083:8083                | 30.0.0 | Armazena dados segmentados.                                                                                                                       |
| Druid MiddleManager | 8091:8091, 8100‚Äì8105     | 30.0.0 | Processa ingest√µes.                                                                                                                               |
| Druid Router        | 8888:8888                | 30.0.0 | Interface web e roteamento de APIs.                                                                                                               |
| Apache Ranger Admin | 6080:6080                | 2.4.0  | Interface de administra√ß√£o de pol√≠ticas de seguran√ßa e auditoria.                                           |
| Apache Ranger MySQL | 3306:3306                | 8.0.33 | Banco de dados para persist√™ncia de configura√ß√µes do Ranger.                                               |
| Apache Solr         | 8983:8983                | 8.11.2 | Backend para logs de auditoria do Ranger.                                                                  |

---


üîé *Observa√ß√£o:*

**Confluentinc**: Distribui√ß√£o da Confluent que integra Kafka e Zookeeper com ferramentas adicionais. A imagem `confluentinc/cp-kafka:6.1.1` **inclui Kafka 2.8.2 e Zookeeper 3.7.2**, de acordo com a [tabela de interoperabilidade da Confluent](https://docs.confluent.io/platform/6.1/installation/versions-interoperability.html#interoperability-versions).


<div align="center">
  <img src="./assets/containers_docker.png" alt="Containers Docker" width="800"/>
  <p><em>Figura 1: Containers Docker</em></p>
</div>

---

## 5. Guia de Uso

### Pr√©-requisitos

* Docker
* Docker Compose
* Git

### Instala√ß√£o

1. Clone o projeto:

```bash
git clone https://github.com/filipe-oliv95/kafka-druid-pipeline.git
cd kafka-druid-pipeline
```

2. Suba os containers:

```bash
docker compose up -d
```

### Teste do Laborat√≥rio

#### Cria√ß√£o da Tabela

Acesse o container PostgreSQL e crie a tabela de exemplo:

```bash
docker exec -it postgres psql -U druid -d druid

CREATE TABLE products (
  id SERIAL PRIMARY KEY,
  name TEXT NOT NULL,
  price DECIMAL
);
```

#### Cria√ß√£o do Conector Debezium

Execute o comando abaixo em um terminal Linux para criar o conector:

```bash
curl -X POST http://localhost:8085/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "postgres-products-connector",
    "config": {
      "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
      "plugin.name": "pgoutput",
      "database.hostname": "postgres",
      "database.port": "5432",
      "database.user": "druid",
      "database.password": "FoolishPassword",
      "database.dbname": "druid",
      "database.server.name": "druidserver",
      "table.include.list": "public.products",
      "slot.name": "products_slot",
      "publication.autocreate.mode": "filtered",
      "database.include.schema.changes": "false",
      "tombstones.on.delete": "false",
      "key.converter": "org.apache.kafka.connect.json.JsonConverter",
      "key.converter.schemas.enable": "false",
      "value.converter": "org.apache.kafka.connect.json.JsonConverter",
      "value.converter.schemas.enable": "false",
      "topic.prefix": "products",
      "decimal.handling.mode": "double"
    }
  }'
```

> Obs: para excluir o conector:
>
> ```bash
> curl -X DELETE http://localhost:8085/connectors/postgres-products-connector  
> ```


#### Verifica√ß√£o de T√≥picos Kafka

```bash
docker exec -it kafka bash
kafka-topics --bootstrap-server localhost:9092 --list
```

<div align="center">
  <img src="./assets/topicos_kafka.png" alt="T√≥picos Kafka padr√£o" width="800"/>
  <p><em>Figura 2: T√≥picos Kafka padr√£o</em></p>
</div>

#### Inser√ß√£o de Dados no PostgreSQL

```bash
docker exec -it postgres psql -U druid -d druid

INSERT INTO products (name, price) VALUES
('Terno', 500.00);
```

#### Verifica√ß√£o do T√≥pico Kafka

```bash
docker exec -it kafka bash
kafka-topics --bootstrap-server localhost:9092 --list
```

<div align="center">
  <img src="./assets/topicos_kafka_2.png" alt="Novo t√≥pico Kafka criado" width="800"/>
  <p><em>Figura 3: Novo t√≥pico Kafka criado</em></p>
</div>


#### Consumindo T√≥picos no Druid

# Consumindo T√≥picos no Druid

1. **Acesse a interface do Druid**

      Abra o navegador e v√° at√© o console do Druid:  
      [http://localhost:8888/](http://localhost:8888/)

2. **Inicie o processo de ingest√£o de dados via Kafka**

      No menu lateral, v√° em:  
      **Load Data** ‚Üí **Streaming** ‚Üí **Kafka**

3. **Configure a conex√£o com o Kafka**

      Preencha os seguintes campos:

      - `Bootstrap servers`: `kafka:9092`  
      > Endere√ßo do broker Kafka que o Druid ir√° se conectar.

      - `Topic`: `products.public.products`  
      > Nome do t√≥pico Kafka que cont√©m os dados a serem consumidos.

      Ap√≥s preencher, clique em **Apply**.

      <div align="center">
         <img src="./assets/topicos_kafka_web.png" alt="Configura√ß√£o do t√≥pico Kafka no Druid" width="800"/>
         <p><em>Figura 4: Configura√ß√£o do t√≥pico Kafka no Druid</em></p>
      </div>

4. **Avance para o pr√≥ximo passo**

      Clique em **Next: Parse Data** para continuar com a defini√ß√£o do formato dos dados recebidos.

5. **Parse Data**

      Os dados est√£o no formato Debezium Envelope. Voc√™ precisa flattenar os campos de `payload.after`.

      - **Data format:** json
      - Clique em **Flatten JSON**

      No painel de "Parsed Fields", clique em **Add flatten field** e adicione os seguintes campos:

      | Name      | JSONPath         |
      |-----------|------------------|
      | id        | `$.after.id`     |
      | name      | `$.after.name`   |
      | price     | `$.after.price`  |
      | ts_ms     | `$.ts_ms`        |

      Clique em **Apply** e depois em **Next: Parse time**.

6. **Parse Time**

      Voc√™ pode usar o timestamp do evento Debezium:

      - Selecione a coluna `ts_ms` e clique em **Next: Transform**

7. **Transforma√ß√µes (opcional)**

      Aqui √© poss√≠vel aplicar transforma√ß√µes nos dados antes da ingest√£o, como renomear colunas, aplicar filtros ou express√µes.

      - Se n√£o for necess√°rio transformar os dados neste momento, apenas clique em **Next: Filter**.

8. **Filtros (opcional)**

      Permite filtrar os dados que ser√£o ingeridos, com base em condi√ß√µes nos campos.

      - Caso deseje ingerir todos os dados, clique diretamente em **Next: Configure schema**.

9. **Configure schema**

      Clique em **Explicitly specify schema** e defina as seguintes configura√ß√µes:

      | Column Name | Type   |
      |-------------|--------|
      | id          | LONG   |
      | name        | STRING |
      | price_raw   | DOUBLE |
      | scale       | LONG   |
      | ts_ms       | LONG   |

      Ap√≥s configurar, clique em **Next: Tune**.

10. **Partition**

      - Segment granularity: **hour**
      - Query granularity: **none** ou **minute**
      - Rollup: **false** (caso voc√™ queira armazenar todos os eventos exatamente como vieram)

         Clique em **Next: Tune**.

11. **Tune**

      Deixe o padr√£o e clique em **Next: Publish**.

12. **Publica√ß√£o da Tarefa de Ingest√£o**

      - D√™ um nome √† ingest√£o, como `products_stream`.
      - Revise todas as configura√ß√µes.
      - Clique em **Submit** para iniciar o processo.

13. **Acesso ao Datasource**

      Ap√≥s a publica√ß√£o da tarefa de ingest√£o, o novo datasource estar√° dispon√≠vel na aba **Datasources** da interface do Druid.

      Voc√™ poder√°:

      - Visualizar os dados diretamente na interface do Druid.
      - Utilizar a aba **Query** para executar comandos SQL.
      - Acessar o datasource via API utilizando a [SQL API do Druid](https://druid.apache.org/docs/latest/api-reference/sql-api).
---

#### Interface Ranger

Ap√≥s subir os servi√ßos, acesse a interface web do Apache Ranger: [http://localhost:6080/](http://localhost:6080/)
```bash
usu√°rio: admin
senha: Ranger1234
```

<div align="center">
   <img src="./assets/ranger_interface.png" alt="Interface do Apache Ranger" width="800"/>
   <p><em>Figura 5: Interface do Apache Ranger</em></p>
</div>

---

## 6. Conclus√£o

Este projeto demonstrou, de forma pr√°tica, a constru√ß√£o de um fluxo de dados em tempo real utilizando tecnologias modernas de streaming:

* **PostgreSQL** como fonte de dados transacionais;
* **Debezium** para captura de altera√ß√µes (CDC) via replica√ß√£o l√≥gica;
* **Kafka** como barramento de eventos distribu√≠do;
* **Druid** como plataforma anal√≠tica para ingest√£o e visualiza√ß√£o de dados.

A arquitetura implementada permite que qualquer altera√ß√£o na base PostgreSQL seja refletida em tempo real nos dashboards do Druid. Essa abordagem √© altamente escal√°vel, ideal para sistemas de monitoramento, an√°lise de logs, m√©tricas de neg√≥cios, entre outros casos de uso orientados a eventos.

Com o ambiente todo orquestrado via Docker Compose, a replica√ß√£o do laborat√≥rio em outras m√°quinas √© simples, facilitando testes, aprendizado e expans√£o para projetos maiores.

Para controle de seguran√ßa e auditoria centralizada, a stack inclui tamb√©m o Apache Ranger e o Solr, oferecendo rastreabilidade das a√ß√µes e pol√≠ticas refinadas de acesso.

---

## 7. Refer√™ncias

 [Kafka Docker-Compose Reference - GitHub](https://github.com/adityajoshi12/kafka-nodejs)

 [Druid Docker-Compose Reference - GitHub](https://github.com/apache/druid/tree/33.0.0#)

 [Ranger Docker-Compose Reference - GitHub](https://github.com/takezoe/ranger-docker/)

 [Druid Documentation](https://druid.apache.org/docs/latest/tutorials/docker)

 [SQL API do Druid](https://druid.apache.org/docs/latest/api-reference/sql-api).